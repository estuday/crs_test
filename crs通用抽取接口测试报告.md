# CRS通用抽取接口测试报告

## 测试说明

本报告对CRS通用抽取接口（大模型版）进行测试，每个接口测试的样本数为3，报告记录接口的成功率、返回内容以及耗时情况。其中耗时情况仅供参考。

本次测试默认抽取所有支持的属性，抽取接口可根据提供的doc_id直接测试。

本报告测试所有接口详细信息请参阅CRS通用抽取接口说明.md，所有采用数据存放于代码路径下的example目录下。



## 文件上传接口

本接口共测试个文件，文件具体大小在对应接口中标明，由于测试文件数量过多，只展示一个返回样例。

**测试结果：**

| 文件数 | 成功率 |
| ------ | ------ |
| 15     | 100%   |

**返回样例：**

```json
{
    "code": 200,
    "message": "处理成功",
    "data": null,
    "doc_id": "a88c6b72d6684230ad3285f5a572cb95"
}
```



## 岗位信息抽取接口

**测试结果：**

| 测试序号 | 文件名                           | 文件大小（MB） | doc_id                           | 耗时（/s） | 调用次数 | 成功率 |
| -------- | -------------------------------- | -------------- | -------------------------------- | ---------- | -------- | ------ |
| 1        | 新一代信息技术岗位能力标准V1.pdf | 4.37           | a88c6b72d6684230ad3285f5a572cb95 | 3.91       | 1        | 100%   |
| 2        | 人工智能产业人才岗位能力要求.pdf | 1.38           | ed37c1653c5b463eb71edb5803e605f3 | 22.07      | 1        | 100%   |
| 3        | 人工智能岗位体系设计.docx        | 0.048          | fa2d18c9dd0d4beea312fd52dc36ad21 | 6.47       | 1        | 100%   |

**返回样例：**

**测试序号1：**

```json
{
    "code": 200,
    "message": "处理成功",
    "data": {
        "介绍说明": "None",
        "岗位需求来源": "[None]"
    },
    "doc_id": "a88c6b72d6684230ad3285f5a572cb95"
}
```

**测试序号2：**

```json
{
    "code": 200,
    "message": "处理成功",
    "data": {
        "介绍说明": "知识图谱研发工程师岗位的介绍说明包括专业知识、技术技能、工程实践和综合能力四个方面。专业知识方面，需要掌握领域知识的定向爬取、深度提取和挖掘，知识抽取、知识表示、知识融合、知识存储、知识推理、知识嵌入等基本算法和流程，以及知识图谱成熟和前沿的算法，例如将知识图谱与深度学习技术的融合与应用，熟悉机器学习、自然语言处理（命名实体识别，关系抽取，句法分析等）和数据挖掘基础。技术技能方面，需要掌握RDF、OWL等知识表示语言，Protege等本体建模工具，Neo4j、AllegroGraph 、Virtuoso等图数据库的使用，常见的爬虫框架如Scrapy，并利用自然语言处理预处理获取的数据，深度学习常用的算法模型，对CNN与RNN有深入的理解，扎实的编程开发基础，熟练掌握C/C++、Python、Java等编程语言，熟悉Linux开发环境，深度学习基本算法原理及数据处理框架，熟悉TensorFlow 、Keras、Caffe、PyTorch等框架，并行计算基本原理及分布式计算框架，熟悉Hadoop、Spark等分布式开发环境。工程实践方面，需要具备丰富的项目经验，至少拥有一个领域知识图谱完整的构建和应用经验，具备复杂系统的设计与架构能力，能解决工具选择、性能优化等问题，能够快速选择并实现知识图谱构建过程中所需要的常见算法，准确理解业务需求，提供相应的解决方案，具备丰富的大数据处理以及数据挖掘经验，具备一定的自然语言处理实践能力。综合能力方面，需要能够根据不同领域的需求，设计并构建适合的知识图谱，并应用解决实际问题，能够深入分析知识图谱应用各个方面要求，实现知识图谱的优化，能够将知识图谱应用到搜索引擎、推荐系统、对话系统、辅助决策。",
        "岗位需求来源": "[None]"
    },
    "doc_id": "ed37c1653c5b463eb71edb5803e605f3"
}
```

**测试序号3：**

```json
{
    "code": 200,
    "message": "处理成功",
    "data": {
        "介绍说明": "深度学习工程师岗位的介绍说明（描述）是：应用深度学习算法技术，解决各行业中的实际业务问题，探索人工智能与机器学习领域前沿技术进展的专业技术人员。",
        "岗位需求来源": "[None]"
    },
    "doc_id": "fa2d18c9dd0d4beea312fd52dc36ad21"
}
```



## 技能信息抽取接口

**测试结果：**

| 测试序号 | 文件名                                        | 文件大小（MB） | doc_id                           | 耗时（/s） | 调用次数 | 成功率 |
| -------- | --------------------------------------------- | -------------- | -------------------------------- | ---------- | -------- | ------ |
| 1        | 大数据工程技术人员_国家职业技术技能标准.pdf   | 4.62           | ffcb9b62b0c14dd899007dd8bd9ca0e1 | 6.98       | 1        | 100%   |
| 2        | 人工智能工程技术人员_国家职业技术技能标准.pdf | 0.4            | f9ad63c5600f419cab8a42346a60962e | 10.75      | 1        | 100%   |
| 3        | 人工智能数据处理职业技能等级标准.pdf          | 0.45           | a90252ec862e47b89e0a5cc9bbfac23e | 14.95      | 1        | 100%   |

**测试序号1：**

```json
{
    "code": 200,
    "message": "处理成功",
    "data": {
        "介绍说明": "None",
        "关键词": "[数据挖掘]",
        "复杂度": "None",
        "技能层次": "None",
        "技能类型": "None",
        "技能工作案例": "None"
    },
    "doc_id": "ffcb9b62b0c14dd899007dd8bd9ca0e1"
}
```

**测试序号2：**

```json
{
    "code": 200,
    "message": "处理成功",
    "data": {
        "介绍说明": "None",
        "关键词": "[人工智能, 技术咨询]",
        "复杂度": "困难",
        "技能层次": "None",
        "技能类型": "专业技术",
        "技能工作案例": "None"
    },
    "doc_id": "f9ad63c5600f419cab8a42346a60962e"
}
```

**测试序号3：**

```json
{
    "code": 200,
    "message": "处理成功",
    "data": {
        "介绍说明": "数据标注技能的介绍说明是：能够根据特定的需求场景，通过人工智能标注平台制定标注模板以及标注任务。能够对使用人工智能标注平台过程中产生的数据进行收集和分析。能够整理、反馈数据标注质量并输出相应的报告。能够使用Python等工具编写脚本实现不同类型的数据批量化标注。",
        "关键词": "[数据标注, 人工智能标注平台, Python]",
        "复杂度": "较难",
        "技能层次": "方法层",
        "技能类型": "专业技术",
        "技能工作案例": "[能够根据特定的需求场景，通过人工智能标注平台制定标注模板以及标注任务。, 能够对使用人工智能标注平台过程中产生的数据进行收集和分析。, 能够整理、反馈数据标注质量并输出相应的报告。, 能够使用Python等工具编写脚本实现不同类型的数据批量化标注。]"
    },
    "doc_id": "a90252ec862e47b89e0a5cc9bbfac23e"
}
```



## 课程信息抽取接口

**测试结果：**

| 测试序号 | 文件名                                     | 文件大小（MB） | doc_id                           | 耗时（/s） | 调用次数 | 成功率 |
| -------- | ------------------------------------------ | -------------- | -------------------------------- | ---------- | -------- | ------ |
| 1        | 大语言模型_教学大纲【高职标准版】.docx     | 0.048          | 3559691a309d437cb0deda6c1b249533 | 54.24      | 1        | 100%   |
| 2        | 数据挖掘与应用_教学大纲【高职标准版】.docx | 0.052          | bbb180c05ff24a31917e68934e70b299 | 57.02      | 1        | 100%   |
| 3        | 自然语言处理_教学大纲【本科标准版】.docx   | 0.056          | c52c8adcdefd4a809d56693ddb038812 | 54.9       | 1        | 100%   |

**测试序号1：**

```json
{
    "code": 200,
    "message": "处理成功",
    "data": {
        "介绍说明": "本课程旨在为高职学生介绍大模型的发展历程、核心技术和实践应用，内容涵盖大模型的基本概述、语言模型和词向量表示、大模型的核心技术Transformer、以及大模型的预训练和微调技术。课程结合电商、政法和教育等领域的案例进行实战演练。通过循序渐进的理论学习和项目实践，学生可以了解大模型的技术成果及应用价值，掌握大模型的基本原理和实用技能，为未来从事大模型相关工作打下基础，并具备参与企业大模型项目的初步能力。",
        "语言": "汉语",
        "复杂度": "较难",
        "学分": "4学分",
        "学时": "70学时",
        "理论学时": "38学时",
        "实践学时": "32学时",
        "学期": "None",
        "学校": "人工智能学院",
        "院系": "[人工智能学院]",
        "专业": "[人工智能技术应用]",
        "课程层次": "高职专科",
        "课程类型": "专业选修",
        "教学模式": "['理论教学', '实践教学']",
        "授课方法": "[讲授]",
        "考核模式": "['考查']",
        "考核标准": "[平时成绩, 期末考核（平台）, 期末考核（学校）]",
        "课程目标": "['了解大语言模型的基本概念、发展历程、应用领域，培养学生学习兴趣、引导学生关注学科前沿和业界动态', '理解自然语言的分词策略、文本表示、词向量表示方法、语言模型以及Seq2Seq序列、注意力机制和Transformer等核心技术架构', '理解大语言模型的预训练基础和常见的微调方法，能够识别不同业务场景下适用的微调策略，并在专业人员指导下应用这些策略', '理解提示学习的基本概念和核心思想，掌握基本的提示设计技巧，能够根据任务需求设计简单的提示词，以指导大语言模型完成特定任务', '能够依据教程和文档，使用开源项目和工具（如Gradio、Streamlit、LangChain等）搭建简单的业务场景应用，并熟悉大语言模型基本的部署流程']",
        "教学思政": "[培养学生的实践技能、创新意识、职业道德和社会责任感。课程强调数据隐私保护、技术伦理和社会主义核心价值观，引导学生将个人发展与国家战略相结合，增强团队合作和社会参与意识，鼓励终身学习，以适应技术发展和社会需求，为成为社会主义建设者和接班人奠定基础。]"
    },
    "doc_id": "3559691a309d437cb0deda6c1b249533"
}
```

**测试序号2：**

```json
{
    "code": 200,
    "message": "处理成功",
    "data": {
        "介绍说明": "数据挖掘与应用课程的介绍说明（描述）是：\n\n通过本课程学习，学生应达到的预期教学目标如下：\n1. 了解数据挖掘的基本概念、发展历程、应用领域以及Web挖掘技术的一般流程和数据挖掘常用工具；\n2. 理解数据挖掘常用算法的核心思想、各算法的联系与区别以及适用场景，并能够根据具体的业务场景选择构建合适的数据挖掘模型；\n3. 掌握数据挖掘常用分类、聚类、回归和关联分析等算法的模型构建与训练流程、性能评估、超参数调优以及推理与部署等工程实践能力；\n4. 培养学生的创新创造与知识迁移能力，引导学生关注数据挖掘领域的最新研究进展和技术趋势，通过阅读行业报告和跟进行业发展趋势，培养学生的自主学习能力和终身学习意识。",
        "语言": "汉语",
        "复杂度": "较难",
        "学分": "3学分",
        "学时": "58学时",
        "理论学时": "28学时",
        "实践学时": "30学时",
        "学期": "None",
        "学校": "人工智能学院",
        "院系": "[人工智能学院]",
        "专业": "[人工智能技术应用]",
        "课程层次": "None",
        "课程类型": "None",
        "教学模式": "['理论教学', '实践教学']",
        "授课方法": "['讲授']",
        "考核模式": "['考查']",
        "考核标准": "[考查]",
        "课程目标": "['了解数据挖掘的基本概念、发展历程、应用领域以及Web挖掘技术的一般流程和数据挖掘常用工具', '理解数据挖掘常用算法的核心思想、各算法的联系与区别以及适用场景，并能够根据具体的业务场景选择构建合适的数据挖掘模型', '掌握数据挖掘常用分类、聚类、回归和关联分析等算法的模型构建与训练流程、性能评估、超参数调优以及推理与部署等工程实践能力', '培养学生的创新创造与知识迁移能力，引导学生关注数据挖掘领域的最新研究进展和技术趋势，通过阅读行业报告和跟进行业发展趋势，培养学生的自主学习能力和终身学习意识']",
        "教学思政": "['三、课程思政\\r\n本课旨在培养学生的社会责任感和职业道德，强调在数据挖掘实践中遵守法律法规，尊重数据隐私，注重数据安全，防止数据泄露和滥用。同时，课程鼓励学生保持科学精神和创新思维，通过团队合作和项目实践，提升沟通能力和解决复杂问题的能力。此外，课程还注重培养学生的终身学习意识，激发他们为社会服务和贡献国家的热情，同时教育学生在数据分析中保持客观和批判性思维，以及在算法设计中追求公平正义，减少偏见，从而在数据挖掘领域成为具有高度社会责任感和专业素养的人才']"
    },
    "doc_id": "bbb180c05ff24a31917e68934e70b299"
}
```

**测试序号3：**

```json
{
    "code": 200,
    "message": "处理成功",
    "data": {
        "介绍说明": "本课程系统讲解了自然语言处理的基本概念、核心技术和主要应用，内容涵盖文本数据处理技术、规则自然语言处理、统计自然语言处理、语言模型与词向量表示、循环神经网络、Seq2Seq架构、注意力机制与Transformer、预训练模型的使用和模型的压缩与裁剪等内容以及在情感分析、机器翻译、智能问答、摘要生成和信息抽取等任务场景中的技术实践，旨在通过理论讲解和项目实践相结合的方式，帮助学生深入理解自然语言处理的基础原理和应用技术，了解国内外自然语言处理技术的发展概貌，具备运用基本原理和常用方法解决问题的能力，同时为以后从事自然语言处理与大模型相关的工作奠定基础。",
        "语言": "汉语",
        "复杂度": "较难",
        "学分": "4学分",
        "学时": "90学时",
        "理论学时": "42学时",
        "实践学时": "48学时",
        "学期": "None",
        "学校": "人工智能学院",
        "院系": "[人工智能学院]",
        "专业": "[人工智能、数据科学与大数据技术]",
        "课程层次": "普通本科",
        "课程类型": "专业选修",
        "教学模式": "['理论教学', '实践教学']",
        "授课方法": "[讲授]",
        "考核模式": "['考查']",
        "考核标准": "None",
        "课程目标": "['了解自然语言处理的基本概念、发展历程、应用场景以及研究方向与常规流程', '理解文本语料数据清洗与表示的操作方法以及K-means聚类、隐马尔科夫模型、条件随机场和朴素贝叶斯等常用的统计自然语言处理方法', '理解RNN循环神经网络、seq2seq网络架构、注意力机制、Transformer和模型的压缩与剪裁的基本概念、核心原理以及实现流程', '掌握预训练模型的调用与微调技术以及在情感分析、机器翻译、智能问答、摘要生成和信息抽取等经典任务场景中的实践技能', '能够按照指定的任务描述，利用所学知识和技术，选择合适的自然语言处理模型，根据性能需求、进行调优，建成模型，完成模型的部署与评估']",
        "教学思政": "['三、课程思政\\r\n本课程通过自然语言处理技术的讲解和实践，强调自主创新和问题解决的重要性，激发学生的创新创造意识和爱国情怀。借助于科大讯飞人工智能实验平台，培育学生在掌握这一前沿技术的理论和方法的同时，具备社会责任意识和担当精神，将个人发展与国家发展相结合，使自然语言处理的应用场景拓展到更多社会公共服务中；同时引导学生深刻理解自然语言处理技术背后涉及的伦理和道德问题，加强学生在工程实践中的责任意识、道德意识、底线意识，更好地推动深度学习技术的发展和应用，从而为我国在人工智能领域取得领先优势，推动全球科技产业发展作出贡献']"
    },
    "doc_id": "c52c8adcdefd4a809d56693ddb038812"
}
```



## 章节信息抽取接口

**测试结果：**

| 测试序号 | 文件名                                         | 文件大小（MB） | doc_id                           | 耗时（/s） | 调用次数 | 成功率 |
| -------- | ---------------------------------------------- | -------------- | -------------------------------- | ---------- | -------- | ------ |
| 1        | 《人工智能基础》课程教学大纲.pdf               | 0.8            | 15edd1a2b5ef4bf69be97c53ae682b62 | 17.99      | 1        | 100%   |
| 2        | 信息检索与推荐技术_教学大纲【本科标准版】.docx | 0.044          | 9e7d8a04d7164b5e9259c1a8e4af6853 | 14.61      | 1        | 100%   |
| 3        | 知识图谱_课程大纲.pdf                          | 0.226          | a3faaad3d3ff401bbb48d46be18fd1f7 | 20.5       | 1        | 100%   |

**测试序号1：**

```json
{
    "code": 200,
    "message": "处理成功",
    "data": {
        "介绍说明": "第2章 Python编程基础  \n教学内容：  \n1) 分支结构的概念与应用  \n2) 遍历循环、条件循环、循环嵌套的应用  \n3) 程序的基本调试方法  \n4) 常用的第三方库介绍与导入方式  \n5) 设计开发一个 Python程序  \n重点与难点：程序流程结构的应用、分支结构的嵌套、循环嵌套、程序的异常处理与捕获。",
        "复杂度": "较难",
        "教学模式": "['理论教学', '实践教学']",
        "学时": "3",
        "章节教学说明": "['了解字符串的基本运算和常见操作', '了解顺序结构、 分支结构和循环结构', '能够掌握程序的基本调试方法', '能够导入 常见的第三方库']",
        "章节教学目标": "None",
        "教学思政": "None"
    },
    "doc_id": "15edd1a2b5ef4bf69be97c53ae682b62"
}
```

**测试序号2：**

```json
{
    "code": 200,
    "message": "处理成功",
    "data": {
        "介绍说明": "None",
        "复杂度": "None",
        "教学模式": "['实践教学']",
        "学时": "2学时",
        "章节教学说明": "None",
        "章节教学目标": "None",
        "教学思政": "None"
    },
    "doc_id": "9e7d8a04d7164b5e9259c1a8e4af6853"
}
```

**测试序号3：**

```json
{
    "code": 200,
    "message": "处理成功",
    "data": {
        "介绍说明": "知识图谱的表示章节的介绍说明（描述）是：本课程系统性介绍知识图谱的基本概念、核心技术内涵和应用实践方法，具体内容涉及知识表示与推理、图数据库、关系抽取与知识图谱构建、知识图谱表示学习与嵌入、语义搜索与知识问答、图神经网络与图挖掘分析等。课程内容的设计以“基础、前沿与实践”相结合为基本原则，既包括基本概念介绍和实践应用内容，也包括学术界的最新前沿进展的介绍。",
        "复杂度": "较简单",
        "教学模式": "['理论教学']",
        "学时": "2",
        "章节教学说明": "[第二周, 3, 2, 1, 第二章知识图谱的表示, 2.1 什么是知识表示, 2.2 人工智能历史发展长河中的知识表示, 2.3 知识图谱的符号表示方法, 2.4 知识图谱的向量表示方法]",
        "章节教学目标": "None",
        "教学思政": "None"
    },
    "doc_id": "a3faaad3d3ff401bbb48d46be18fd1f7"
}
```



## 专业信息抽取接口

**测试结果：**

| 测试序号 | 文件名                                                       | 文件大小（MB） | doc_id                           | 耗时（/s） | 调用次数 | 成功率 |
| -------- | ------------------------------------------------------------ | -------------- | -------------------------------- | ---------- | -------- | ------ |
| 1        | 杭州电子科技大学信息工程学院计算机学院人工智能微专业培养方案.docx | 0.016          | edb9eef1c9384eff9a78f16f556ba2b8 | 29.46      | 1        | 100%   |
| 2        | 上海理工大学语言智能微专业培养方案.pdf                       | 0.157          | fe54442050bc48eba8dfeb218192e0ee | 30.82      | 1        | 100%   |
| 3        | 唯众高职人工智能技术应用专业解决方案.pdf                     | 3.11           | 58e2d7397d954a0a8f253980ce0fc6e0 | 28.73      | 1        | 100%   |

**测试序号1：**

```json
{
    "code": 200,
    "message": "处理成功",
    "data": {
        "介绍说明": "人工智能的介绍说明（描述）是：在掌握原有专业知识技能的基础上，掌握人工智能的基础知识，具备人工智能技术应用素养，能正确理解工作中碰到的人工智能技术问题，具备一定的解决相关问题的能力，能在各自工作岗位中发挥具备人工智能技术应用思维优势，具有一定的判断能力和可持续发展能力，培养既有优秀的专业素养又具备良好人工智能技能的复合型应用人才。",
        "院系": "None",
        "专业代码": "None",
        "专业类别": "人工智能的专业类别是微专业。",
        "学科门类": "人工智能属于计算机学科门类。",
        "学位": "None",
        "学制": "基本学制为两年。",
        "毕业要求": "[掌握人工智能的基本理论和知识, 具有使用常用人工智能算法框架的良好能力, 具有计算思维能力，具备人工智能算法研发和应用的基本素质和能力, 了解人工智能技术的发展现状和趋势, 具有良好的实践操作能力和可持续发展能力]",
        "专业相关证书": "None",
        "专业相关职业": "[人工智能开发工程师, 数据科学家, 机器学习工程师, 深度学习工程师, 人工智能研究员, 人工智能产品经理]"
    },
    "doc_id": "edb9eef1c9384eff9a78f16f556ba2b8"
}
```

**测试序号2：**

```json
{
    "code": 200,
    "message": "处理成功",
    "data": {
        "介绍说明": "语言智能微专业是在世界科技迅猛发展，国家提出大力发展人工智能战略，以及新文科建设的背景下设置的跨学科交叉融合专业。微专业的依托专业为国家级一流本科专业建设点、国内首个QSStars五星认证本科专业“英语专业”，由上海理工大学外语学院和光电信息与计算机工程学院合作共建，并邀请语言智能企业专家参与；遴选一批从事人工智能、自然语言处理、计算机技术、认知神经科学、语言数据智能处理与分析方向的专家和优秀教师共同完成理论、实践/实验教学任务。微专业旨在培养能够胜任语言信息智能处理和开发、大数据挖掘和分析、认知神经实验操作，能够参与语言人工智能开发工作的跨学科、复合型、宽视野、重实践、通学术的高级工程技术人才。",
        "院系": "[上海理工大学外语学院, 光电信息与计算机工程学院]",
        "专业代码": "None",
        "专业类别": "语言智能的专业类别是跨学科交叉融合专业。",
        "学科门类": "语言智能属于跨学科交叉融合专业。",
        "学位": "None",
        "学制": "学制：1年",
        "毕业要求": "[修满10学分]",
        "专业相关证书": "[上海理工大学颁发的“语言智能”微专业证书]",
        "专业相关职业": "[语言信息智能处理和开发, 大数据挖掘和分析, 认知神经实验操作, 语言人工智能开发工作]"
    },
    "doc_id": "fe54442050bc48eba8dfeb218192e0ee"
}
```

**测试序号3：**

```json
{
    "code": 200,
    "message": "处理成功",
    "data": {
        "介绍说明": "人工智能应用技术专业注重强化学生的人工智能建模与算法分析设计能力、解决交通、医疗等行业人工智能应用问题的实践能力，强调学生的个性化科学思维和创新实践能力的培养；培养能够进行人工智能算法分析与设计、人工智能核心技术研究与开发、人工智能技术应用与其它专业领域结合等复杂工程问题分析与解决的高级专门人才。",
        "院系": "[唯众高职]",
        "专业代码": "None",
        "专业类别": "人工智能技术应用专业",
        "学科门类": "人工智能应用技术专业属于工学学科门类。",
        "学位": "None",
        "学制": "None",
        "毕业要求": "[人工智能产品和系统的生产、测试、运营、维护、技术支持、售后、销售等工作，对于能力较强的学生可以承担人工智能助理工程师、机器学习工程师、计算机视觉工程师等研发岗。具体岗位包括 :人工智能实施工程师、人工智能运营工程师、人工智能运维工程师、人工智能助理工程师、人工智能测试工程师、人工智能技术支持工程师（FAE）、人工智能工程师、机器学习工程师、人工智能产品销售。]",
        "专业相关证书": "None",
        "专业相关职业": "[人工智能实施工程师, 人工智能运维工程师, 人工智能助理工程师, 人工智能测试工程师, 人工智能技术支持工程师（FAE）, 人工智能工程师, 机器学习工程师, 人工智能产品销售]"
    },
    "doc_id": "58e2d7397d954a0a8f253980ce0fc6e0"
}
```

## 资源信息抽取接口

**测试结果：**

| 测试序号 | 文件名                     | 文件大小（MB） | 耗时（/s） | 调用次数 | 成功率 |
| -------- | -------------------------- | -------------- | ---------- | -------- | ------ |
| 1        | 3.1-语音识别概念2.mp4      | 32.8           | 16.64      | 1        | 100%   |
| 2        | IS-1.4-A-语音信号分析.pptx | 2.4            | 6.12       | 1        | 100%   |
| 3        | IS-1.5-B-语音特征提取.docx | 3.11           | 61.49      | 1        | 100%   |

**测试序号1：**

```json
{
    "code": 200,
    "message": "处理成功",
    "data": {
        "resourcetype": "视频",
        "name": "3.1-语音识别概念2.mp4",
        "filesize": 32.85,
        "videotime": 447.87
    },
    "doc_id": null
}
```

**测试序号2：**

```json
{
    "code": 200,
    "message": "处理成功",
    "data": {
        "resourcetype": "课件",
        "name": "IS-1.4-A-语音信号分析.pptx",
        "description": "《智能语音》",
        "keywords": [
            "语音",
            "信号",
            "特征"
        ],
        "filesize": 2.41
    },
    "doc_id": null
}
```

**测试序号3：**

```json
{
    "code": 200,
    "message": "处理成功",
    "data": {
        "resourcetype": "讲义",
        "name": "IS-1.5-B-语音特征提取.docx",
        "description": "《语音特征提取》讲义语音特征提取是语音数字信号处理中的一个核心环节，它涉及从语音信号中提取具有代表性和区分性的特征参数，以便用于语音识别、语音合成、说话人识别等应用。本节将学习常用的语音特征提取方法，包括短时能量、短时过零率、梅尔频率倒谱系数（MFCC）等。",
        "keywords": [
            "信号",
            "c++",
            "频率"
        ],
        "filesize": 3.11
    },
    "doc_id": null
}
```



## 知识点抽取接口

### 标准版

**测试结果：**

| 测试序号 | 文件名                         | 耗时（/s） | 调用次数 | 成功率 |
| -------- | ------------------------------ | ---------- | -------- | ------ |
| 1        | LLM-5.2-智慧政法.docx          | 24.18      | 1        | 100%   |
| 2        | ML-5.3-B-稀疏核机_v230218.docx | 23.24      | 1        | 100%   |
| 3        | NLP-6.16-B-机器翻译(二).docx   | 31.3       | 1        | 100%   |

**测试序号1：**

```json
{
    "code": 200,
    "message": "处理成功",
    "data": {
        "knowledge": "法律大模型",
        "description": "法律大模型是一种利用人工智能技术，通过大量法律数据的训练，能够提供准确、及时的法律咨询服务的系统。它旨在解决律师数量有限且收费昂贵的问题，满足个人和企业对专业法律意见和指导的需求。",
        "data_id": "ed97ece5105f4775bbac71cef5d36e53"
    }
}{
    "code": 200,
    "message": "处理成功",
    "data": {
        "knowledge": "模型微调技术",
        "description": "模型微调技术是一种在已有的大型预训练模型基础上，通过调整部分参数来适应特定任务或数据集的方法。这种技术可以显著减少计算资源的需求，同时保持模型的性能。常见的微调方法包括Adapter微调、Prefix tuning和Lora微调等。",
        "data_id": "72609e24d3aa4a118581baabe2310877"
    }
}{
    "code": 200,
    "message": "处理成功",
    "data": {
        "knowledge": "适配器调优",
        "description": "适配器调优是一种在预训练模型中插入特定于任务的参数，以减少下游任务微调时的计算资源消耗的方法。通过冻结模型主体并仅训练这些适配器参数，可以有效降低算力需求。",
        "data_id": "8d3d238a51a346c4b40b853220029f81"
    }
}{
    "code": 200,
    "message": "处理成功",
    "data": {
        "knowledge": "P-tuning",
        "description": "P-tuning是一种针对大型语言模型的soft prompt方法，通过引入可微分的virtual token来优化prompt的设计，提高模型对prompt的敏感性。与Prefix Tuning不同，P-tuning仅在输入层添加virtual token，并且其位置不固定于前缀，提供了更多的灵活性。",
        "data_id": "1ceb3cfddf2f4929ada084c67cd339d3"
    }
}{
    "code": 200,
    "message": "处理成功",
    "data": {
        "knowledge": "LoRa技术",
        "description": "LoRa技术是一种通过秩分解来约束更新矩阵ΔW的秩，从而减少模型微调所需时间和空间的技术。它将更新矩阵表示为两个低秩矩阵的乘积，并在训练时使用随机高斯初始化和零初始化。这种技术可以单独存储更新矩阵的向量，在推理时只需与基座模型合并即可，无需额外消耗推理时间。",
        "data_id": "ac4e40d0fffa4f4ca4b068f839cb3641"
    }
}
```

**测试序号2：**

```json
{
    "code": 200,
    "message": "处理成功",
    "data": {
        "knowledge": "虚拟环境管理",
        "description": "虚拟环境管理是一种软件工程实践，用于创建隔离的软件开发环境，以避免不同项目间的库依赖冲突。通过使用如Anaconda3这样的工具，开发者可以更有效地管理项目所需的第三方库和其版本。",
        "data_id": "09a06688581944f1951e6efebf0deb5b"
    }
}{
    "code": 200,
    "message": "处理成功",
    "data": {
        "knowledge": "稀疏核机",
        "description": "稀疏核机是一种基于核的算法，它通过只依赖于训练数据点的一个子集来计算核函数，从而对新数据的预测进行加速。这种方法解决了传统核方法在计算上的不可行性和效率问题。",
        "data_id": "da01c17794894a6d944b9e8435a65db5"
    }
}{
    "code": 200,
    "message": "处理成功",
    "data": {
        "knowledge": "支持向量机",
        "description": "支持向量机是一种用于分类和回归问题的监督学习模型，它通过构建一个或多个超平面来在多维空间中进行数据分类。",
        "data_id": "10698bbc08734b5fbbd63424363778d2"
    }
}{
    "code": 200,
    "message": "处理成功",
    "data": {
        "knowledge": "二次规划",
        "description": "二次规划是一种数学优化问题，涉及在一组线性约束条件下最小化或最大化一个二次函数。通过将对偶理论，可以将原始问题转化为对偶问题，从而在某些情况下简化问题的求解过程。",
        "data_id": "21f848c54dd94807bf30bd236b77c5ae"
    }
}{
    "code": 200,
    "message": "处理成功",
    "data": {
        "knowledge": "松弛变量",
        "description": "松弛变量是支持向量机（SVM）中用于处理数据点不完全可分情况的一种技术。它允许某些数据点在分类边界的错误一侧，从而放宽了硬边缘的限制，形成了一个软边缘。通过引入松弛变量，可以优化模型的泛化能力，同时保持对大多数数据点的准确分类。",
        "data_id": "1cd2d11bfd704e45825fcbab53ee6456"
    }
}
```

**测试序号3：**

```json
{
    "code": 200,
    "message": "处理成功",
    "data": {
        "knowledge": "人工评价方法",
        "description": "人工评价方法是一种由人类评审员对机器翻译结果进行评估的方法，评审员通常是双语专家，他们根据一定的标准对翻译质量进行评分。评价标准包括忠实度和流利度。",
        "data_id": "b2fa0e6a0d004c89b95f52ee6f8a3fbc"
    }
}{
    "code": 200,
    "message": "处理成功",
    "data": {
        "knowledge": "自动评价方法",
        "description": "自动评价方法是利用计算机程序对机器翻译结果进行评估，通过比较机器译文与参考译文的相似度来计算翻译质量得分。BLEU是一种常用的自动评价指标，通过统计机器译文与参考译文中n元文法（n-gram）的匹配情况来衡量翻译质量。",
        "data_id": "c86bc537d8754cc49f44bb0026e19db0"
    }
}{
    "code": 200,
    "message": "处理成功",
    "data": {
        "knowledge": "Transformer模型",
        "description": "Transformer是一种基于注意力机制的深度学习模型，由Vaswani等人在2017年提出。它主要用于自然语言处理任务，如机器翻译，并因其高效性和准确性而受到广泛关注。",
        "data_id": "72065696e48d4ba9b85ce7a4e865657a"
    }
}{
    "code": 200,
    "message": "处理成功",
    "data": {
        "knowledge": "Transformer 输入表示",
        "description": "Transformer模型的输入由单词Embedding和位置Embedding相加得到，其中单词Embedding可以通过预训练算法如Word2Vec、Glove等获取，也可以在Transformer中训练得到。位置Embedding用于表示单词在句子中的位置。",
        "data_id": "1d196104ef47451eb246abcb5b205d73"
    }
}{
    "code": 200,
    "message": "处理成功",
    "data": {
        "knowledge": "多头注意力机制",
        "description": "多头注意力机制是一种通过组合多个自注意力层来增强模型表达能力的技术，它允许模型在不同的表示子空间中并行学习信息。",
        "data_id": "cec34b8bbacd4e7b9d7a657166a08bb1"
    }
}{
    "code": 200,
    "message": "处理成功",
    "data": {
        "knowledge": "Transformer编码器结构",
        "description": "Transformer的编码器由多头注意力机制、加法与归一化层以及前馈神经网络组成。这些组件共同工作，以处理输入数据并生成输出表示。",
        "data_id": "f00599e0b5de49d9bd01695881719137"
    }
}{
    "code": 200,
    "message": "处理成功",
    "data": {
        "knowledge": "Transformer Decoder",
        "description": "Transformer的Decoder结构与Encoder相似，但包含两个Multi-Head Attention层。第一个层使用Masked操作，第二个层的K, V矩阵使用Encoder的编码信息矩阵C进行计算，而Q使用上一个Decoder的输出。",
        "data_id": "d74ff1be8a3149448f4c951717c62863"
    }
}
```



### 聚类版

**测试结果：**

| 测试序号 | 文件名                         | 耗时（/s） | 调用次数 | 成功率 |
| -------- | ------------------------------ | ---------- | -------- | ------ |
| 1        | LLM-5.2-智慧政法.docx          | 6.8        | 1        | 100%   |
| 2        | ML-5.3-B-稀疏核机_v230218.docx | 11.11      | 1        | 100%   |
| 3        | NLP-6.16-B-机器翻译(二).docx   | 31.3       | 1        | 100%   |

**测试序号1：**

```json
{
    "code": 200,
    "message": "处理成功",
    "data": {
        "knowledge": "大模型微调技术及其变种",
        "description": "大模型微调技术及其变种，如Adapter、P-tuning和LoRa，是针对大型预训练语言模型进行高效微调的方法。这些技术通过引入可训练的适配器层或参数高效的调整策略，使得在保持模型性能的同时，显著减少计算资源和时间的消耗。",
        "data_id": "3f30827d10c14a70a3e96efcf0f0f7f6"
    }
}
```

**测试序号2：**

```json
{
    "code": 200,
    "message": "处理成功",
    "data": {
        "knowledge": "支持向量机理论与应用",
        "description": "支持向量机是一种监督学习模型，主要用于分类和回归问题。它通过寻找最大化类别间隔的超平面来实现数据分类，适用于高维空间的数据。在实际应用中，支持向量机常用于文本分类、图像识别等领域。",
        "data_id": "0f7c8e07940b414db51c3d763a4415ad"
    }
}{
    "code": 200,
    "message": "处理成功",
    "data": {
        "knowledge": "重叠类分布",
        "description": "重叠类分布是一种统计概念，用于描述两个或多个概率分布之间的重叠程度。它通常用于分析不同数据集之间的关系，特别是在分类问题中，以评估不同类别之间的相似性或差异性。通过计算重叠区域的大小，可以量化不同分布之间的重叠程度，从而为决策提供依据。",
        "data_id": "dccf15822b82458da0c69fbf041728a4"
    }
}
```

**测试序号3：**

```json
{
    "code": 200,
    "message": "处理成功",
    "data": {
        "knowledge": "机器翻译模型评价方法",
        "description": "机器翻译模型评价方法主要包括人工评价和自动评价两大类。人工评价依赖于专业译员对译文质量进行主观判断，而自动评价则通过计算译文与参考译文之间的相似度、流畅度等指标来量化评估。两者结合可以更全面地衡量机器翻译模型的性能。",
        "data_id": "5fca5a70b31d40ff8409b186aae7ee6d"
    }
}{
    "code": 200,
    "message": "处理成功",
    "data": {
        "knowledge": "基于Transformer的机器翻译模型介绍",
        "description": "基于Transformer的机器翻译模型是一种先进的自然语言处理技术，它利用多头注意力机制和编码器-解码器结构来提高翻译的准确性和效率。该模型通过自注意力机制捕捉输入序列中的全局依赖关系，并通过编码器和解码器的协同工作实现高效的机器翻译。",
        "data_id": "eb1b92f9295d441a8b763aff1daceda7"
    }
}
```



### 知识点查询

**特殊说明：**

*本接口可能不符合接口说明中的响应参数，原因是部分属性抽取效果不好，所以取消了部分属性的处理。data中有效的属性目前只有name，description和data。*

**测试结果：**

| 测试序号 | 知识点                | 知识点id                         | 耗时(/ms) | 调用次数 | 成功率 |
| -------- | --------------------- | -------------------------------- | --------- | -------- | ------ |
| 1        | Transformer编码器结构 | f00599e0b5de49d9bd01695881719137 | 29        | 1        | 100%   |
| 2        | LoRa技术              | ac4e40d0fffa4f4ca4b068f839cb3641 | 32        | 1        | 100%   |
| 3        | 支持向量机            | 10698bbc08734b5fbbd63424363778d2 | 20        | 1        | 100%   |

**测试序号1：**

```json
{
    "code": 200,
    "message": "处理成功",
    "data": {
        "_id": "f00599e0b5de49d9bd01695881719137",
        "name": "Transformer编码器结构",
        "description": "Transformer的编码器由多头注意力机制、加法与归一化层以及前馈神经网络组成。这些组件共同工作，以处理输入数据并生成输出表示。",
        "data": [
            "3.3 Encoder 结构",
            "上图红色部分是 Transformer 的 Encoder block 结构，可以看到是由 Multi-Head Attention, Add & Norm, Feed Forward, Add & Norm 组成的。刚刚已经了解了 Multi-Head Attention 的计算过程，现在了解一下 Add & Norm 和 Feed Forward 部分。",
            "Add & Norm 层由 Add 和 Norm 两部分组成，其计算公式如下：",
            "其中X表示Multi-Head Attention或者Feed Forward的输入，MultiHeadAttention(X) 和 FeedForward(X) 表示输出（输出与输入X维度是一样的，所以可以相加）。",
            "Add指 X+MultiHeadAttention(X)，是一种残差连接，通常用于解决多层网络训练的问题，可以让网络只关注当前差异的部分，在 ResNet 中经常用到：",
            "图9 残差连接",
            "Norm指 Layer Normalization，通常用于RNN结构，Layer Normalization 会将每一层神经元的输入都转成均值方差都一样的，这样可以加快收敛。",
            "Feed Forward 层比较简单，是一个两层的全连接层，第一层的激活函数为Relu，第二层不使用激活函数，对应的公式如下。",
            "X是输入，Feed Forward 最终得到的输出矩阵的维度与X一致。",
            "通过上面描述的 Multi-Head Attention, Feed Forward, Add & Norm 就可以构造出一个 Encoder block，Encoder block 接收输入矩阵，并输出一个矩阵。通过多个 Encoder block 叠加就可以组成 Encoder。",
            "第一个 Encoder block 的输入为句子单词的表示向量矩阵，后续 Encoder block 的输入是前一个 Encoder block 的输出，最后一个 Encoder block 输出的矩阵就是编码信息矩阵C，这一矩阵后续会用到Decoder中。"
        ],
        "keywords": []
    }
}
```

**测试序号2：**

```json
{
    "code": 200,
    "message": "处理成功",
    "data": {
        "_id": "ac4e40d0fffa4f4ca4b068f839cb3641",
        "name": "LoRa技术",
        "description": "LoRa技术是一种通过秩分解来约束更新矩阵ΔW的秩，从而减少模型微调所需时间和空间的技术。它将更新矩阵表示为两个低秩矩阵的乘积，并在训练时使用随机高斯初始化和零初始化。这种技术可以单独存储更新矩阵的向量，在推理时只需与基座模型合并即可，无需额外消耗推理时间。",
        "data": [
            "2.3 LoRa",
            "LoRA技术使用秩分解来约束更新矩阵 ΔW 的秩，它将 ΔWₙₖ 表示为 2 个低秩矩阵 Bₙᵣ 和 Aᵣₖ 的乘积，r<<min(n,k)。A使用随机高斯初始化，B初始为0。这样在训练时训练的参数量从（nk）减少到r（n+k），大大减少了模型微调所需要的时间与空间。另外，更新矩阵的向量可以单独存储，在推理时只需和基座模型合并即可，无需消耗额外的推理时间，同时面对不同的任务只需切换不同lora权重即可。"
        ],
        "keywords": []
    }
}
```

**测试序号3：**

```json
{
    "code": 200,
    "message": "处理成功",
    "data": {
        "_id": "10698bbc08734b5fbbd63424363778d2",
        "name": "支持向量机",
        "description": "支持向量机是一种用于分类和回归问题的监督学习模型，它通过构建一个或多个超平面来在多维空间中进行数据分类。",
        "data": [
            "（1）最大边缘分类器",
            "我们首先通过一个二分类问题引出支持向量机，然后再讨论其与核函数的关系。假设线性基函数模型为：",
            "       公式（1）",
            "其中ϕ(x)表⽰一个固定的特征空间变换，并且我们显式地写出了偏置参数b。注意，我们会简要介绍使用核函数表达的对偶形式，这避免了显式地在特征空间中进⾏计算。训练数据集由N个输⼊向量x1,…, xN组成，对应的目标值为t1,…, tN，其中，新的数据点x根据y(x)的符号进行分类。",
            "现阶段，我们假设训练数据集在特征空间中是线性可分的，即根据定义，存在⾄少一个参数w和b的选择方式，使得对于tn = +1的点，函数（1）都满⾜y(xn) > 0，对于tn = −1的点，都有y(xn) < 0，从而对于所有训练数据点，都有tny(xn) > 0。",
            "当然，存在许多能够把类别精确分开的解。在这与感知器一节中的定义相同，在感知器算法中，它能够保证在有限步骤之内找到一个解。然而，它找到的这个解依赖于w和b的（任意的）初始值选择，还依赖于数据点出现的顺序。如果有多个能够精确分类训练数据点的解，那么我们应该尝试寻找泛化错误最小的那个解。支持向量机解决这个问题的方法是：引⼊边缘（margin）的概念，这个概念被定义为决策边界与任意样本之间的最⼩距离，如图1所⽰。",
            "图1: 边缘被定义为决策边界与最近的数据点之间的垂直距离，如左图所⽰。最⼤化边缘会⽣成对决策边界的一个特定的选择，如右图所⽰。这个决策边界的位置由数据点的一个⼦集确定，被称为支持向量，⽤圆圈表⽰。",
            "在⽀持向量机中，决策边界被选为使边缘最大化的那个决策边界。采用最⼤边缘解的动机可以通过计算学习理论（computational learning theory）或者统计学习理论（statistical learning theory）进行理解。然⽽， Tong and Koller（2000）给出了使⽤最大边缘解的⼀个简单的原因。他们考察了⼀个基于生成式⽅法和判别式方法组成的金字塔的分类框架，并且首先使⽤带有共同参数σ2的高斯核的Parzen密度估计对每个类别的输⼊向量x的分布进行建模。伴随着类别先验，这个分布定义了一个最优的分类错误率决策边界。然⽽，他们没有使用这个最优的决策边界，⽽是通过最小化学习到的模型的错误率来寻找最优的超平⾯。在极限的情况下，可以证明最优超平面是有着最大边缘的超平面。这个结果背后的直观含义是，随着σ2的减小，距离超平面较近的点对超平面的控制能力逐渐大于距离较远的点。在极限情况下，超平面会变得与非支持向量的数据点无关。这就是支持向量机稀疏性的来源，对于那些有决定意义的点，我们就称之为支持向量，因此这种方法就叫做支持向量机。",
            "在线性分类中，根据图2，点x距离由y(x) = 0定义的超平⾯的垂直距离。",
            "图2: 二维线性判别函数的几何表⽰。决策面（红色）垂直与w，它距离原点的偏移量由偏置参数w0控制。此外，一个⼀般的点x与决策面的有符号的正交距离为y(x)/|| w||。",
            "其中y(x)的函数形式由公式（1）给出。此外，我们感兴趣的是那些能够正确分类所有数据点的解，即对于所有的n都有，因此点距离决策面的距离为：",
            "         公式（2）",
            "边缘由数据集里垂直距离最近的点xn给出，我们希望最优化参数w和b，使得这个距离能够最大化。因此，最大边缘解可以通过下式得到：",
            "  公式（3）",
            "其中我们将因子提到了对n的最优化之外，因为w与n无关。直接求解这个最优化问题相当复杂，因此我们要把它转化为一个更容易求解的等价问题。为了完成这件事，我们注意到如果我们进行重新标度以及，那么任意点xn距离决策面的距离不会发生改变。我们可以使⽤这个性质，对于距离决策面最近的点，令：",
            "        公式（4）",
            "在这种情况下，所有的数据点会满足限制：",
            "  公式（5）",
            "这被称为决策超平面的标准表示。对于使上式取得等号的数据点，我们说限制被激活（active），对于其他的数据点，我们说限制未激活（inactive）。根据定义，总会存在至少一个激活限制，因为总会有一个距离最近的点，并且一旦边缘被最大化，会有至少两个激活的限制。这样，最优化问题就简化为了最大化，这等价于最小化，因此我们要在限制条件（公式5）下，求解最优化问题：",
            "         公式（6）",
            "公式（6）的因子的引⼊是为了后续计算⽅便。这是二次规划（quadratic programming）问题的一个例⼦，其中我们试图在一组线性不等式的限制条件下最⼩化二次函数。似乎偏置b从最优化问题中消失了。然⽽，它可以通过限制条件隐式地确定，因为这些限制条件要求的改变需要通过b的改变进行补偿。我们稍后会看到它是如何工作的。",
            "为了解决这个限制的最优化问题，我们引入拉格朗日乘数≥ 0。公式（5）中的每个限制条件都对应着一个乘数。从而可得下面的拉格朗日函数：",
            "  公式（7）",
            "其中。注意拉格朗日乘数项前面的负号，因为我们要关于w和b最⼩化，关于最大化。令关于w和b的导数等于零，我们得到了下面两个条件:",
            "        公式（8）",
            "            公式（9）",
            "使用这两个条件从中消去w和b，就得到了最⼤化边缘问题的对偶表示（dual representation），其中我们要关于a最大化：",
            "  公式（10）",
            "限制条件为：",
            "            公式（11）",
            "                   公式（12）",
            "这⾥，核函数被定义为。与之前⼀样，这是一个二次规划问题，其中我们要在不等式限制条件下最优化一个的二次函数。我们会在下一节讨论求解这种二次规划问题的⽅法。"
        ],
        "keywords": []
    }
}
```



### 知识点所属段落

**测试结果：**

| 测试序号 | 知识点                | 知识点id                         | 耗时(/ms) | 调用次数 | 成功率 |
| -------- | --------------------- | -------------------------------- | --------- | -------- | ------ |
| 1        | Transformer编码器结构 | f00599e0b5de49d9bd01695881719137 | 27        | 1        | 100%   |
| 2        | LoRa技术              | ac4e40d0fffa4f4ca4b068f839cb3641 | 31        | 1        | 100%   |
| 3        | 支持向量机            | 10698bbc08734b5fbbd63424363778d2 | 33        | 1        | 100%   |

**测试序号1：**

```json
{
    "code": 200,
    "message": "处理成功",
    "data": {
        "_id": "f00599e0b5de49d9bd01695881719137",
        "data": [
            "3.3 Encoder 结构",
            "上图红色部分是 Transformer 的 Encoder block 结构，可以看到是由 Multi-Head Attention, Add & Norm, Feed Forward, Add & Norm 组成的。刚刚已经了解了 Multi-Head Attention 的计算过程，现在了解一下 Add & Norm 和 Feed Forward 部分。",
            "Add & Norm 层由 Add 和 Norm 两部分组成，其计算公式如下：",
            "其中X表示Multi-Head Attention或者Feed Forward的输入，MultiHeadAttention(X) 和 FeedForward(X) 表示输出（输出与输入X维度是一样的，所以可以相加）。",
            "Add指 X+MultiHeadAttention(X)，是一种残差连接，通常用于解决多层网络训练的问题，可以让网络只关注当前差异的部分，在 ResNet 中经常用到：",
            "图9 残差连接",
            "Norm指 Layer Normalization，通常用于RNN结构，Layer Normalization 会将每一层神经元的输入都转成均值方差都一样的，这样可以加快收敛。",
            "Feed Forward 层比较简单，是一个两层的全连接层，第一层的激活函数为Relu，第二层不使用激活函数，对应的公式如下。",
            "X是输入，Feed Forward 最终得到的输出矩阵的维度与X一致。",
            "通过上面描述的 Multi-Head Attention, Feed Forward, Add & Norm 就可以构造出一个 Encoder block，Encoder block 接收输入矩阵，并输出一个矩阵。通过多个 Encoder block 叠加就可以组成 Encoder。",
            "第一个 Encoder block 的输入为句子单词的表示向量矩阵，后续 Encoder block 的输入是前一个 Encoder block 的输出，最后一个 Encoder block 输出的矩阵就是编码信息矩阵C，这一矩阵后续会用到Decoder中。"
        ],
        "keywords": []
    }
}
```

**测试序号2：**

```json
{
    "code": 200,
    "message": "处理成功",
    "data": {
        "_id": "ac4e40d0fffa4f4ca4b068f839cb3641",
        "data": [
            "2.3 LoRa",
            "LoRA技术使用秩分解来约束更新矩阵 ΔW 的秩，它将 ΔWₙₖ 表示为 2 个低秩矩阵 Bₙᵣ 和 Aᵣₖ 的乘积，r<<min(n,k)。A使用随机高斯初始化，B初始为0。这样在训练时训练的参数量从（nk）减少到r（n+k），大大减少了模型微调所需要的时间与空间。另外，更新矩阵的向量可以单独存储，在推理时只需和基座模型合并即可，无需消耗额外的推理时间，同时面对不同的任务只需切换不同lora权重即可。"
        ],
        "keywords": []
    }
}
```

**测试序号3：**

```json
{
    "code": 200,
    "message": "处理成功",
    "data": {
        "_id": "10698bbc08734b5fbbd63424363778d2",
        "data": [
            "（1）最大边缘分类器",
            "我们首先通过一个二分类问题引出支持向量机，然后再讨论其与核函数的关系。假设线性基函数模型为：",
            "       公式（1）",
            "其中ϕ(x)表⽰一个固定的特征空间变换，并且我们显式地写出了偏置参数b。注意，我们会简要介绍使用核函数表达的对偶形式，这避免了显式地在特征空间中进⾏计算。训练数据集由N个输⼊向量x1,…, xN组成，对应的目标值为t1,…, tN，其中，新的数据点x根据y(x)的符号进行分类。",
            "现阶段，我们假设训练数据集在特征空间中是线性可分的，即根据定义，存在⾄少一个参数w和b的选择方式，使得对于tn = +1的点，函数（1）都满⾜y(xn) > 0，对于tn = −1的点，都有y(xn) < 0，从而对于所有训练数据点，都有tny(xn) > 0。",
            "当然，存在许多能够把类别精确分开的解。在这与感知器一节中的定义相同，在感知器算法中，它能够保证在有限步骤之内找到一个解。然而，它找到的这个解依赖于w和b的（任意的）初始值选择，还依赖于数据点出现的顺序。如果有多个能够精确分类训练数据点的解，那么我们应该尝试寻找泛化错误最小的那个解。支持向量机解决这个问题的方法是：引⼊边缘（margin）的概念，这个概念被定义为决策边界与任意样本之间的最⼩距离，如图1所⽰。",
            "图1: 边缘被定义为决策边界与最近的数据点之间的垂直距离，如左图所⽰。最⼤化边缘会⽣成对决策边界的一个特定的选择，如右图所⽰。这个决策边界的位置由数据点的一个⼦集确定，被称为支持向量，⽤圆圈表⽰。",
            "在⽀持向量机中，决策边界被选为使边缘最大化的那个决策边界。采用最⼤边缘解的动机可以通过计算学习理论（computational learning theory）或者统计学习理论（statistical learning theory）进行理解。然⽽， Tong and Koller（2000）给出了使⽤最大边缘解的⼀个简单的原因。他们考察了⼀个基于生成式⽅法和判别式方法组成的金字塔的分类框架，并且首先使⽤带有共同参数σ2的高斯核的Parzen密度估计对每个类别的输⼊向量x的分布进行建模。伴随着类别先验，这个分布定义了一个最优的分类错误率决策边界。然⽽，他们没有使用这个最优的决策边界，⽽是通过最小化学习到的模型的错误率来寻找最优的超平⾯。在极限的情况下，可以证明最优超平面是有着最大边缘的超平面。这个结果背后的直观含义是，随着σ2的减小，距离超平面较近的点对超平面的控制能力逐渐大于距离较远的点。在极限情况下，超平面会变得与非支持向量的数据点无关。这就是支持向量机稀疏性的来源，对于那些有决定意义的点，我们就称之为支持向量，因此这种方法就叫做支持向量机。",
            "在线性分类中，根据图2，点x距离由y(x) = 0定义的超平⾯的垂直距离。",
            "图2: 二维线性判别函数的几何表⽰。决策面（红色）垂直与w，它距离原点的偏移量由偏置参数w0控制。此外，一个⼀般的点x与决策面的有符号的正交距离为y(x)/|| w||。",
            "其中y(x)的函数形式由公式（1）给出。此外，我们感兴趣的是那些能够正确分类所有数据点的解，即对于所有的n都有，因此点距离决策面的距离为：",
            "         公式（2）",
            "边缘由数据集里垂直距离最近的点xn给出，我们希望最优化参数w和b，使得这个距离能够最大化。因此，最大边缘解可以通过下式得到：",
            "  公式（3）",
            "其中我们将因子提到了对n的最优化之外，因为w与n无关。直接求解这个最优化问题相当复杂，因此我们要把它转化为一个更容易求解的等价问题。为了完成这件事，我们注意到如果我们进行重新标度以及，那么任意点xn距离决策面的距离不会发生改变。我们可以使⽤这个性质，对于距离决策面最近的点，令：",
            "        公式（4）",
            "在这种情况下，所有的数据点会满足限制：",
            "  公式（5）",
            "这被称为决策超平面的标准表示。对于使上式取得等号的数据点，我们说限制被激活（active），对于其他的数据点，我们说限制未激活（inactive）。根据定义，总会存在至少一个激活限制，因为总会有一个距离最近的点，并且一旦边缘被最大化，会有至少两个激活的限制。这样，最优化问题就简化为了最大化，这等价于最小化，因此我们要在限制条件（公式5）下，求解最优化问题：",
            "         公式（6）",
            "公式（6）的因子的引⼊是为了后续计算⽅便。这是二次规划（quadratic programming）问题的一个例⼦，其中我们试图在一组线性不等式的限制条件下最⼩化二次函数。似乎偏置b从最优化问题中消失了。然⽽，它可以通过限制条件隐式地确定，因为这些限制条件要求的改变需要通过b的改变进行补偿。我们稍后会看到它是如何工作的。",
            "为了解决这个限制的最优化问题，我们引入拉格朗日乘数≥ 0。公式（5）中的每个限制条件都对应着一个乘数。从而可得下面的拉格朗日函数：",
            "  公式（7）",
            "其中。注意拉格朗日乘数项前面的负号，因为我们要关于w和b最⼩化，关于最大化。令关于w和b的导数等于零，我们得到了下面两个条件:",
            "        公式（8）",
            "            公式（9）",
            "使用这两个条件从中消去w和b，就得到了最⼤化边缘问题的对偶表示（dual representation），其中我们要关于a最大化：",
            "  公式（10）",
            "限制条件为：",
            "            公式（11）",
            "                   公式（12）",
            "这⾥，核函数被定义为。与之前⼀样，这是一个二次规划问题，其中我们要在不等式限制条件下最优化一个的二次函数。我们会在下一节讨论求解这种二次规划问题的⽅法。"
        ],
        "keywords": []
    }
}
```

